{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    " \n",
    "class DataSplitter:\n",
    "    def __init__(self, part):\n",
    "        self.part = part\n",
    "    \n",
    "    def split(self, folder, train, test):\n",
    "        filenames = os.listdir(folder)\n",
    "        for (i, fname) in enumerate(filenames):\n",
    "            src = os.path.join(folder, fname)\n",
    "            if (i % self.part) == 0:\n",
    "                dst = os.path.join(test, fname)\n",
    "            else:\n",
    "                dst = os.path.join(train, fname)\n",
    "        copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSplitter(10)\n",
    "ds.split(r\"C:\\Faces\\UTKFace\", r\"C:\\Faces\\Training\", r\"C:\\Faces\\Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class ResizeConverter:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def convert(self, image):\n",
    "        return cv2.resize(image, (self.width, self.height), cv2.INTER_AREA)\n",
    "    \n",
    "class GrayConverter:\n",
    "    def convert(self, image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254, 254, 253, ..., 253, 254, 254],\n",
       "       [254, 254, 253, ..., 253, 254, 254],\n",
       "       [254, 254, 253, ..., 253, 254, 254],\n",
       "       ...,\n",
       "       [251, 245, 191, ..., 116, 107, 150],\n",
       "       [248, 231, 161, ..., 119, 109, 151],\n",
       "       [246, 208, 166, ..., 121, 112, 154]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(r\"C:\\Faces\\Training\\9_1_4_20170103213057382.jpg\")\n",
    "converter = ResizeConverter(128, 128)\n",
    "image = converter.convert(image)\n",
    "converter = GrayConverter()\n",
    "image = converter.convert(image)\n",
    "cv2.imwrite(r\"C:\\Faces\\Results\\12_0_0_20170110224804208.png\", image)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class ImageDataset:\n",
    "    def __init__(self, converters):\n",
    "        self.converters = converters\n",
    "\n",
    "    def get_files(self, folder):\n",
    "        filenames = os.listdir(folder)\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            yield filepath\n",
    "        \n",
    "    def load(self, folder):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        files = list(self.get_files(folder))\n",
    "        for (i, path) in enumerate(files):\n",
    "            image = cv2.imread(path)\n",
    "            fname = os.path.basename(path)\n",
    "            label = fname.split('_')[0]\n",
    "            if self.converters is not None:\n",
    "                for c in self.converters:\n",
    "                    image = c.convert(image)\n",
    "            self.images.append(image)\n",
    "            self.labels.append(int(label))\n",
    "            \n",
    "    def save(self, folder):\n",
    "        for (i, image) in enumerate(self.images):\n",
    "            filepath = os.path.join(folder, str(self.labels[i])+\"_\"+str(i)+\".png\")\n",
    "            cv2.imwrite(filepath, image)\n",
    "\n",
    "    def get_data(self):\n",
    "        return (np.array(self.images), np.array(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "class AgeClassConverter:\n",
    "    @staticmethod\n",
    "    def convert(imdataset, ageranges):\n",
    "        (images, labels) = imdataset.get_data()\n",
    "        arrays = []\n",
    "        for (i, image) in enumerate(images):\n",
    "            arr = img_to_array(image, data_format=\"channels_last\")\n",
    "            arrays.append(arr)\n",
    "        arrays = np.array(arrays).astype(\"float\")/255.0  \n",
    "        \n",
    "        k = len(ageranges)\n",
    "        for (i, label) in enumerate(labels):\n",
    "            for (j, r) in enumerate(ageranges):\n",
    "                if j<(k-1) and label>=ageranges[j] and label<ageranges[j+1]:\n",
    "                    labels[i] = j+1\n",
    "                    break\n",
    "        \n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit(range(1, k));\n",
    "        binlabels = np.array(lb.transform(labels))\n",
    "        \n",
    "        return (arrays, binlabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ResizeConverter(128, 128)\n",
    "gc = GrayConverter()\n",
    "dataset = ImageDataset([rc, gc])\n",
    "dataset.load(r\"C:\\Faces\\Training\")\n",
    "dataset.save(r\"C:\\Faces\\Results\")\n",
    "(images, labels) = dataset.get_data()\n",
    "(trainData, trainLabels) = AgeClassConverter.convert(dataset, [1, 11, 21, 31, 41, 51, 61, 81, 101])\n",
    "#labels\n",
    "#trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "class ClassLeNet:\n",
    "    @staticmethod\n",
    "    def create(width, height, kernels, hidden, classes):\n",
    "        net = Sequential()\n",
    "        \n",
    "        net.add(Conv2D(kernels, (5, 5), padding=\"same\", input_shape=(height, width, 1)))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization())\n",
    "        \n",
    "        net.add(Conv2D(kernels, (5, 5), padding=\"same\"))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization())\n",
    "        net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        net.add(Conv2D(kernels, (3, 3), padding=\"same\"))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization())\n",
    "        \n",
    "        net.add(Conv2D(kernels, (3, 3), padding=\"same\"))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization())\n",
    "        net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        net.add(Flatten())\n",
    "        net.add(Dense(hidden))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(Dropout(0.5))\n",
    "        \n",
    "        net.add(Dense(hidden))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        \n",
    "        net.add(Dense(classes))\n",
    "        net.add(Activation(\"softmax\"))\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Loading testing set...\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ageranges = [1, 6, 11, 16, 19, 22, 31, 45, 61, 81, 101]\n",
    "classes = len(ageranges)-1\n",
    "imgsize = 128\n",
    "rc = ResizeConverter(imgsize, imgsize)\n",
    "gc = GrayConverter()\n",
    "\n",
    "print(\"Loading training set...\")\n",
    "trainSet = ImageDataset([rc, gc])\n",
    "trainSet.load(r\"C:\\Faces\\Training\")\n",
    "(trainData, trainLabels) = AgeClassConverter.convert(trainSet, ageranges)\n",
    "\n",
    "print(\"Loading testing set...\")\n",
    "testSet = ImageDataset([rc, gc])\n",
    "testSet.load(r\"C:\\Faces\\Testing\")\n",
    "(testData, testLabels) = AgeClassConverter.convert(testSet, ageranges)\n",
    "\n",
    "#trainLabels\n",
    "#testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling net...\n",
      "Net compiled.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "print(\"Compiling net...\")\n",
    "opt = SGD(lr=0.01)\n",
    "kernels = 16\n",
    "hidden = 256\n",
    "imgsize = 128\n",
    "net = ClassLeNet.create(imgsize, imgsize, kernels, hidden, classes)\n",
    "net.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Net compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(net, to_file=\"classlenet.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training net...\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 26s 6s/step - loss: 3.7205 - accuracy: 0.0918 - val_loss: 2.3012 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 2.2677 - accuracy: 0.2725 - val_loss: 2.3386 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 23s 6s/step - loss: 1.9232 - accuracy: 0.3236 - val_loss: 2.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.7220 - accuracy: 0.3713 - val_loss: 2.3666 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.6659 - accuracy: 0.4238 - val_loss: 2.3520 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.4003 - accuracy: 0.5105 - val_loss: 2.3421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.2491 - accuracy: 0.5621 - val_loss: 2.3494 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.2143 - accuracy: 0.6234 - val_loss: 2.3177 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.1076 - accuracy: 0.6446 - val_loss: 2.3684 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.0655 - accuracy: 0.6427 - val_loss: 2.3355 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.9528 - accuracy: 0.7010 - val_loss: 2.2924 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.7920 - accuracy: 0.7661 - val_loss: 2.3115 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.7546 - accuracy: 0.7542 - val_loss: 2.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.6902 - accuracy: 0.7982 - val_loss: 2.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6010 - accuracy: 0.8442 - val_loss: 2.2398 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5453 - accuracy: 0.8459 - val_loss: 2.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4855 - accuracy: 0.8899 - val_loss: 2.1964 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4138 - accuracy: 0.8966 - val_loss: 2.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4008 - accuracy: 0.9042 - val_loss: 2.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4098 - accuracy: 0.8948 - val_loss: 2.2116 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: C:\\Faces\\age_class_net_16_256.cnn\\assets\n",
      "Trained net saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training net...\")\n",
    "frep = net.fit(trainData, trainLabels, validation_data=(testData, testLabels), batch_size=128, epochs=20, verbose=1)\n",
    "netname = r\"C:\\Faces\\age_class_net_\"+str(kernels)+\"_\"+str(hidden)+\".cnn\"\n",
    "net.save(netname)\n",
    "print(\"Trained net saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained net...\n",
      "Net loaded.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "agelabels = [\"1-5\", \"6-10\", \"11-15\", \"16-18\", \"19-21\", \n",
    "             \"22-30\", \"31-44\", \"45-60\", \"61-80\", \"81-100\"]\n",
    "netname = r\"C:\\Faces\\age_class_net_16_256.cnn\"\n",
    "print(\"Loading pre-trained net...\")\n",
    "trained_net = load_model(netname)\n",
    "print(\"Net loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalSet = ImageDataset([rc, gc])\n",
    "evalSet.load(r\"C:\\Faces\\Testing\")\n",
    "\n",
    "(evalData, evalLabels) = AgeClassConverter.convert(evalSet, ageranges)\n",
    "evalLabels = evalLabels.argmax(axis=1)\n",
    "predLabels = trained_net.predict(evalData).argmax(axis=1)\n",
    "\n",
    "(evalImages, evalAges) = evalSet.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum testing age = 329.0\n",
      "Testing age err = 0.5045592705167173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ageError = 0.0\n",
    "sumAge = 0.0\n",
    "for (i, l) in enumerate(evalLabels):\n",
    "    age = evalAges[i]\n",
    "    sumAge += age\n",
    "    pli = predLabels[i]\n",
    "    if (pli != l):\n",
    "        if (pli > l):\n",
    "            da = ageranges[pli]-age\n",
    "        else:\n",
    "            da = age-(ageranges[pli+1]-1)\n",
    "        ageError += da\n",
    "ageError /= sumAge\n",
    "\n",
    "print(\"Sum testing age = \"+str(sumAge))\n",
    "print(\"Testing age err = \"+str(ageError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resfolder = r\"C:\\Faces\\Results\"\n",
    "for (i, image) in enumerate(evalImages):\n",
    "    limage = image.copy()\n",
    "    pli = predLabels[i]\n",
    "    cv2.putText(limage, agelabels[pli]+\"(\"+str(ageranges[pli])+\"-\"+str(ageranges[pli+1]-1)+\")\",\n",
    "                (4, 16), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(limage, \"Age: {}\".format(str(evalAges[i])),\n",
    "                (4, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    filepath = os.path.join(resfolder, str(evalAges[i])+\"_\"+str(i)+\".png\")\n",
    "    cv2.imwrite(filepath, limage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "class AgeEstimator:\n",
    "    def __init__(self, converters, net):\n",
    "        self.converters = converters\n",
    "        self.net = net\n",
    "        \n",
    "    def estimate(self, image):\n",
    "        for (i, converter) in enumerate(self.converters):\n",
    "            image = converter.convert(image)    \n",
    "        array = img_to_array(image, data_format=\"channels_last\")\n",
    "        \n",
    "        arrays = []\n",
    "        arrays.append(array)\n",
    "        data = np.array(arrays).astype(\"float\")/255.0  \n",
    "        \n",
    "        prob =  self.net.predict(data)\n",
    "        classes = prob.argmax(axis=1)\n",
    "        class_num = classes[0]\n",
    "        \n",
    "        return class_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "netname = r\"C:\\Faces\\age_class_net_16_256.cnn\"\n",
    "trained_net = load_model(netname)\n",
    "\n",
    "rc = ResizeConverter(128, 128)\n",
    "gc = GrayConverter()\n",
    "estimator = AgeEstimator([rc, gc], trained_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataFolder = r\"C:\\Faces\\Testing\"\n",
    "\n",
    "#imageName = r\"23_0_0_20170116220953152.jpg\"\n",
    "#imageName = r\"25_0_2_20170119163949502.jpg\"\n",
    "#imageName = r\"25_1_0_20170117140903569.jpg\"\n",
    "#imageName = r\"26_0_1_20170116185229362.jpg\"\n",
    "#imageName = r\"29_0_0_20170117202649479.jpg\"\n",
    "#imageName = r\"30_0_0_20170117152309069.jpg\"\n",
    "#imageName = r\"30_0_0_20170117181104996.jpg\"\n",
    "#imageName = r\"30_0_0_20170117181259219.jpg\"\n",
    "#imageName = r\"30_1_0_20170117114647665.jpg\"\n",
    "#imageName = r\"40_0_3_20170117154542505.jpg\"\n",
    "#imageName = r\"41_0_4_20170104173222571.jpg\"\n",
    "\n",
    "imageFile = os.path.join(dataFolder, imageName)\n",
    "image = cv2.imread(imageFile)\n",
    "\n",
    "ageGroup = estimator.estimate(image)\n",
    "\n",
    "ageranges = [1, 6, 11, 16, 21, 24, 27, 31, 45, 61, 81, 101]\n",
    "resultFolder = r\"C:\\Faces\\Results\"\n",
    "cv2.putText(image, \"[\"+str(ageranges[ageGroup])+\"-\"+str(ageranges[ageGroup+1]-1)+\"]\",\n",
    "            (4, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "resultFile = os.path.join(resultFolder, imageName)\n",
    "cv2.imwrite(resultFile, image)\n",
    "\n",
    "ageGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
